# kantts
TTS application based on modelscope KAN-TTS

## Installation
```
pip install modelscope torch onnxruntime onnx pytorch_wavelets
pip install kantts -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html
```

## demo
`python demo.py`
OR
`python read.py` for a more interactive way to run models
## Features - ç‰¹æ€§
- å¢åŠ è¯­é€Ÿè°ƒèŠ‚ï¼Œscaleå‚æ•°è°ƒèŠ‚
- æ¨ç†åŠ é€Ÿ

  * tensorrt is disabled for now as I was not able to install it on my WSL ğŸ¤£ *
  
  1.HifiGAN tensorrtåŠ é€Ÿ
  
  2.sambert tensorrtåŠ é€Ÿ

## HifiGAN tensorrtåŠ é€Ÿ
```
cd tensorrt_onnx
# å¯¼å‡ºhifigan onnx
python hifigan_onnx_export.py 
# åˆ©ç”¨trt.OnnxParserç”Ÿæˆengine
python build_from_onnx.py
```
æœ¬é¡¹ç›®åŸå§‹æ¨¡å‹ç›´æ¥åˆ©ç”¨modelscopeä¸‹è½½
```
from modelscope.utils.constant import Tasks
model_id = 'damo/speech_sambert-hifigan_tts_zh-cn_16k'
sambert_hifigan_tts = pipeline(task=Tasks.text_to_speech, model=model_id)
text = "ä½ å¥½"
output = sambert_hifigan_tts(input=text, voice="zhitian_emo")  # zhibei_emo  zhitian_emo zhiyan_emo  zhizhe_emo
```

## sambert tensorrtåŠ é€Ÿ
ä»£ç è¯·è‡ªè¡Œå®ç°ï¼Œæœ¬é¡¹ç›®æœªå®ç°ï¼Œå¯å‚è€ƒä»¥ä¸‹æ€è·¯ã€‚

ps. ä¸»è¦æ€è·¯æ¥è‡ªkanttsç¾¤çš„å¤§ä½¬  
1ã€ç»Ÿè®¡sambertå„ä¸ªæ¨¡å—è€—æ—¶ï¼Œå‘ç°ä¸»è¦è€—æ—¶éƒ½é›†ä¸­åœ¨MelPNCADecoderï¼›   
2ã€å°†MelPNCADecoderéƒ¨åˆ†ç”±ä¸€ä¸ªå¾ªç¯çš„mel_decå‡½æ•°ç»„æˆï¼›   
å®ƒåœ¨memoryçš„ç¬¬äºŒä¸ªç»´åº¦ä¸Šå¾ªç¯è°ƒç”¨ï¼Œä¸‹ä¸€æ¬¡è°ƒç”¨ä¼šä¾èµ–ä¸Šä¸€æ¬¡çš„ç»“æœ  
3ã€å°†mel_decå‡½æ•°åˆ©ç”¨tensorrt python apié‡å†™ï¼Œå› ä¸ºmel_delçš„è°ƒç”¨ä¼šä¾èµ–ä¸Šä¸€æ¬¡mel_delçš„ä¸­é—´å˜é‡å’Œè¾“å‡ºç»“æœï¼Œæ•…ä¿®æ”¹è¯¥å‡½æ•°è¾“å…¥è¾“å‡ºï¼Œå°†éœ€è¦çš„ä¸­é—´ç»“æœéƒ½è¾“å…¥åˆ°ä¸‹ä¸€æ¬¡è°ƒç”¨ï¼›   

step=0æ—¶å’Œstep>0æ—¶çš„è¾“å…¥ä¸ä¸€è‡´ï¼Œæ‰€æœ‰åªå¯¹step>0æ—¶çš„æ¨ç†éƒ¨åˆ†è¿›è¡Œtensorrtæ­å»ºã€‚

è¾“å…¥éƒ¨åˆ†ï¼š
```
input = network.add_input(
    name="input", dtype=trt.float32, shape=(1, 1, 80))

memory = network.add_input(
    name="memory", dtype=trt.float32, shape=(1, -1, 160))

memory_step = network.add_input(
    name="memory_step", dtype=trt.float32, shape=(1, 1, 160))

pnca_x_attn_mask_step_part1 = network.add_input(
    name="pnca_x_attn_mask_step_part1", dtype=trt.float32, shape=(8, 1, -1))
pnca_x_attn_mask_step_part2 = network.add_input(
    name="pnca_x_attn_mask_step_part2", dtype=trt.float32, shape=(8, 1, 1))

pnca_h_attn_mask_step = network.add_input(
    name="pnca_h_attn_mask_step", dtype=trt.float32, shape=(8, 1, -1))

pre_x_k = network.add_input(
    name="pre_x_k", dtype=trt.float32, shape=(8*12, -1, 16))

pre_x_v = network.add_input(
    name="pre_x_v", dtype=trt.float32, shape=(8*12, -1, 16))
```

æ¨ç†è¾“å…¥è¾“å‡ºè½¬æ¢
```
pnca_x_attn_mask_step_ = pnca_x_attn_mask_step.repeat(8, 1, 1)
pnca_h_attn_mask_step_ = pnca_h_attn_mask_step.repeat(8, 1, 1)

pnca_x_attn_mask_step_part1 = pnca_x_attn_mask_step_[:, :, :-1]
pnca_x_attn_mask_step_part2 = pnca_x_attn_mask_step_[:, :, -1:]

pre_x_k_merge = None
pre_x_v_merge = None
for i in range(len(pre_x_k_list)):
    if i == 0:
        pre_x_k_merge = pre_x_k_list[i]
        pre_x_v_merge = pre_x_v_list[i]
    else:
        pre_x_k_merge = torch.cat([pre_x_k_merge, pre_x_k_list[i]], dim=0)
        pre_x_v_merge = torch.cat([pre_x_v_merge, pre_x_v_list[i]], dim=0)
    # print(pre_x_k_merge.shape)
    # print(pre_x_v_merge.shape)

output_trt = self.trt_model({"input": input, "memory": memory, "memory_step": memory_step,
                    "pnca_x_attn_mask_step_part1": pnca_x_attn_mask_step_part1.float(),
                    "pnca_x_attn_mask_step_part2": pnca_x_attn_mask_step_part2.float(),
                    "pnca_h_attn_mask_step": pnca_h_attn_mask_step_.float(),
                    "pre_x_k": pre_x_k_merge,
                    "pre_x_v": pre_x_v_merge})

dec_output_step = output_trt['output']
dec_pnca_attn_x_step = []
dec_pnca_attn_h_step = []
for i in range(12):
    dec_pnca_attn_x_step += [output_trt[f'dec_pnca_attn_x_{i}']]
    dec_pnca_attn_h_step += [output_trt[f'dec_pnca_attn_h_{i}']]

pre_x_k_list = []
pre_x_v_list = []
for i in range(12):
    pre_x_k_list += [output_trt[f'x_k_{i}']]
    pre_x_v_list += [output_trt[f'x_v_{i}']]
 ```

 æ¨¡å‹æ­å»ºéƒ¨åˆ†
 masked_fillæ–¹æ³•æœ‰ä¸¤ä¸ªå‚æ•°ï¼Œmaskeå’Œvalueï¼Œmaskæ˜¯ä¸€ä¸ªpytorchå¼ é‡ï¼ˆTensorï¼‰ï¼Œå…ƒç´ æ˜¯å¸ƒå°”å€¼ï¼Œvalueæ˜¯è¦å¡«å……çš„å€¼ï¼Œå¡«å……è§„åˆ™æ˜¯maskä¸­å–å€¼ä¸ºTrueä½ç½®å¯¹åº”äºå¾…å¡«å……çš„ç›¸åº”ä½ç½®ç”¨valueå¡«å……ã€‚
ä¾‹å¦‚æœ¬é¡¹ç›®ä¸­ï¼Œéœ€è¦å®ç° 
attn = attn.masked_fill(mask, -np.inf)
å¡«å……å€¼ä¸ºè´Ÿæ— ç©·
trtå®ç°æ­¥éª¤
â— å°†maskç”±boolè½¬æ¢æˆfloat32ï¼Œå˜ä¸ºç”±0å’Œ1ç»„æˆçš„tensor
â— ç„¶åå°†maskåˆ©ç”¨é€å…ƒç´ ç›¸ä¹˜çš„æ–¹å¼ï¼Œä¹˜ä»¥ä¸€ä¸ªå¾ˆå¤§çš„è´Ÿæ•°ï¼Œè¿™é‡Œè®¾ç½®ä¸º-100000000000000000.0
 ```
inf_const = network.add_constant((1,1,1), (-100000000000000000.0)*np.ones((1,1,1)).astype(np.float32))
mask = network.add_elementwise(mask, inf_const.get_output(0), trt.ElementWiseOperation.PROD)
 ```
â— æœ€åattnå’Œmaské€å…ƒç´ ç›¸åŠ 

layernormç®—å­å¯ä»¥ä½¿ç”¨8.6çš„tensorrtï¼Œä¹Ÿå¯ä»¥è‡ªå·±æŒ‰ç…§å…¬å¼å®ç°
